{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2750f96",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This Jupyter notebook describes the case study for the the autonomous systems case study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96976a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pacti.iocontract.utils import getVarlist\n",
    "from PIL import Image\n",
    "from pacti.terms.polyhedra.loaders import readContract, writeContract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9ed711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`polytope` failed to import `cvxopt.glpk`.\n",
      "will use `scipy.optimize.linprog`\n",
      "`omega.symbolic.symbolic` failed to import `dd.cudd`.\n",
      "Will use `dd.autoref`.\n",
      "`tulip` failed to import `cvxopt`.\n",
      "No quadratic cost for controller computation.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import patches\n",
    "import pdb\n",
    "import sys\n",
    "sys.path.append('/Users/apurvabadithela/Documents/software/tulip-control/')\n",
    "from matplotlib.collections import PatchCollection\n",
    "from tulip.transys import MarkovChain as MC\n",
    "from tulip.transys import MarkovDecisionProcess as MDP\n",
    "from itertools import compress, product\n",
    "from tulip.interfaces import stormpy as stormpy_int\n",
    "from tulip.transys.compositions import synchronous_parallel\n",
    "\n",
    "# Importing libraries to setup markov chain\n",
    "# Setting up the base controllers:\n",
    "import design_controller4 as K_des\n",
    "import ped_controller as Kped\n",
    "import not_ped_controller as Kobj\n",
    "import empty_controller as Kempty\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2da66e",
   "metadata": {},
   "source": [
    "## Part 1: Objects that matter for perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df546064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object class definitions\n",
    "object_classes = {\"pedestrian\", \"obstacle\", \"bckgnd\"}\n",
    "CM = dict()\n",
    "for o in object_classes:\n",
    "    CM[\"pred_\"+str(o)] = {\"true_\" + str(o) for o in object_classes}\n",
    "n = len(set(object_classes))\n",
    "\n",
    "def generate_CM_prob_labels(pred_obj, true_obj):\n",
    "    prob_label = \"P(\" + pred_obj + \"| \" + true_obj +\")\"\n",
    "    return prob_label\n",
    "\n",
    "def generate_labels(true_obj):\n",
    "    true_obj_prob_labels = [generate_CM_prob_labels(pred_obj, true_obj) for pred_obj in object_classes]\n",
    "    return true_obj_prob_labels\n",
    "\n",
    "pedestrian_prob_labels = generate_labels(\"pedestrian\")\n",
    "obstacle_prob_labels = generate_labels(\"obstacle\")\n",
    "bckgnd_prob_labels = generate_labels(\"bckgnd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aac64b",
   "metadata": {},
   "source": [
    "## Part 2: System Specifications and System Contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ae3ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TILESIZE = 50\n",
    "ORIENTATIONS = {'n': 270, 'e': 0, 's': 90,'w':180, 'ne':315, 'nw':225, 'se':45, 'sw':135}\n",
    "START_CROSSWALK = -1\n",
    "END_CROSSWALK = 2\n",
    "CROSSWALK_V = 1\n",
    "CROSSWALK_LOCATIONS = dict()\n",
    "ped_loc = []\n",
    "for i, num in enumerate(range(2*START_CROSSWALK,2*(END_CROSSWALK+1))):\n",
    "    CROSSWALK_LOCATIONS.update({i: (num/2, CROSSWALK_V)})\n",
    "    ped_loc.append(num/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a45b28d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class GridCar():\n",
    "    def __init__(self):\n",
    "        self.xc_init = 0\n",
    "        self.vc_init = 0\n",
    "        self.ped = 1\n",
    "        self.N = 10\n",
    "        self.Vmax = 2\n",
    "        self.xped = 10-CROSSWALK_V\n",
    "        self.main_dir = os.path.dirname(os.path.dirname(os.path.realpath(\"__file__\")))\n",
    "        self.car_fig = self.main_dir + '/evaluating_perception/imglib/red_car.png'\n",
    "        self.ped_fig = self.main_dir + '/evaluating_perception/imglib/pedestrian_img.png'\n",
    "        self.car_data = [9, 0]\n",
    "        if self.ped == 1:\n",
    "            self.ped_data = [CROSSWALK_V, min(ped_loc)]\n",
    "        else:\n",
    "            self.ped_data = None\n",
    "    \n",
    "    def dynamics(self):\n",
    "        transitions = dict()\n",
    "        for x in range(0, self.N):\n",
    "            x_succ = []\n",
    "            for v in range(0, self.Vmax):\n",
    "                x_succ.append(x + v)\n",
    "            transitions[x] = x_succ\n",
    "        return transitions\n",
    "    \n",
    "    def plot_grid(self):\n",
    "        size = [1, self.N]\n",
    "        x_min = 0\n",
    "        x_max = size[0] * TILESIZE\n",
    "        y_min = 0\n",
    "        y_max = size[1] * TILESIZE\n",
    "        # x_min, x_max, y_min, y_max = get_map_corners(map)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.axis('equal')\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "        # fill in the road regions\n",
    "        road_tiles = []\n",
    "        width_tiles = np.arange(0,size[0]+1)*2*TILESIZE\n",
    "        lanes_tiles = np.arange(0,size[1]+1)*TILESIZE\n",
    "        \n",
    "        for i in np.arange(0,size[0]):\n",
    "            for k in np.arange(0,size[1]+1):\n",
    "                tile = patches.Rectangle((width_tiles[i],lanes_tiles[k]),2*TILESIZE,TILESIZE,linewidth=1,facecolor='k', alpha=0.4)\n",
    "                road_tiles.append(tile)\n",
    "        ax.add_collection(PatchCollection(road_tiles, match_original=True))\n",
    "\n",
    "        # now add crosswalk on top\n",
    "        crosswalk_tiles = []\n",
    "        for item in CROSSWALK_LOCATIONS.keys():\n",
    "            if item % 2 == 0:\n",
    "                color = 'silver'\n",
    "                alpha = 0.5\n",
    "            else:\n",
    "                color = 'k'\n",
    "                alpha = 0.5\n",
    "            width = CROSSWALK_LOCATIONS[item][0]*TILESIZE\n",
    "            lanes = CROSSWALK_LOCATIONS[item][1]*TILESIZE\n",
    "            tile = patches.Rectangle((width,lanes),TILESIZE/2,TILESIZE,linewidth=1,facecolor=color, alpha=alpha)\n",
    "            crosswalk_tiles.append(tile)\n",
    "        ax.add_collection(PatchCollection(crosswalk_tiles, match_original=True))\n",
    "        # TODO: Add cross-walk tile names next to the cells\n",
    "        plt.gca().invert_yaxis()\n",
    "        return ax\n",
    "    \n",
    "    \n",
    "    def plot_car(self, ax):\n",
    "        y_tile, speed = self.car_data\n",
    "        theta_d = 270 # Rotate car to face north\n",
    "        x = (1) * TILESIZE/2\n",
    "        y = (y_tile) * TILESIZE\n",
    "        car_fig = Image.open(self.car_fig)\n",
    "        car_fig = car_fig.rotate(theta_d, expand=False)\n",
    "        offset = 0.1\n",
    "        ax.imshow(car_fig, zorder=1, interpolation='bilinear', extent=[x+2, x+TILESIZE-2, y+2, y+TILESIZE-2])\n",
    "        return ax\n",
    "    \n",
    "    def plot_ped(self, ax):\n",
    "        y_tile, x_tile = self.ped_data\n",
    "        x = (x_tile) * TILESIZE/2\n",
    "        y = (y_tile) * TILESIZE\n",
    "        ped_fig = Image.open(self.ped_fig)\n",
    "        ped_fig = ped_fig.rotate(180, expand=False)\n",
    "        offset = 0.1\n",
    "        ax.imshow(ped_fig, zorder=1, interpolation='bilinear', extent=[x+4, x+TILESIZE-2, y+2, y+TILESIZE-2])\n",
    "        return ax\n",
    "    \n",
    "    # Function to calculate all system states:\n",
    "    def construct_transitions(self):\n",
    "        T = dict()\n",
    "        for xcar in range(1,self.N+1):\n",
    "            for vcar in range(0, self.Vmax+1):\n",
    "                st = (xcar, vcar)\n",
    "                end_st = []\n",
    "                if xcar == self.N:\n",
    "                    end_st.append((xcar, vcar))\n",
    "                elif vcar == 0:\n",
    "                    xcar_p = min(self.N, xcar+1)\n",
    "                    end_st.append((xcar, vcar))\n",
    "                    end_st.append((xcar_p, vcar+1))\n",
    "                    end_st.append((xcar, vcar+1))\n",
    "                else:\n",
    "                    xcar_p = min(self.N, xcar+vcar)\n",
    "                    end_st.append((xcar_p, vcar))\n",
    "                    end_st.append((xcar_p, vcar-1))\n",
    "                    if vcar < Vhigh:\n",
    "                        end_st.append((xcar_p, vcar+1))\n",
    "                T[st] = end_st\n",
    "        return T\n",
    "    \n",
    "    # System states for pedestrian\n",
    "    def system_states_example_ped(self):\n",
    "        nS = self.N*(self.Vmax+1)\n",
    "        state = lambda x,v: (self.Vmax+1)*(x-1) + v\n",
    "        state_to_S = dict()\n",
    "        S = set()\n",
    "        for xcar in range(1,self.N+1):\n",
    "            for vcar in range(0, self.Vmax+1):\n",
    "                st = \"S\"+str(state(xcar, vcar))\n",
    "                state_to_S[xcar,vcar] = st\n",
    "                S|={st}\n",
    "        T = self.construct_transitions()\n",
    "        return S, state_to_S, T\n",
    "\n",
    "\n",
    "# Generate grid and figure:\n",
    "grid = GridCar()\n",
    "ax = grid.plot_grid()\n",
    "ax = grid.plot_car(ax)\n",
    "ax = grid.plot_ped(ax)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(grid.main_dir + \"/evaluating_perception/imglib/car_ped_ex.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a7541",
   "metadata": {},
   "source": [
    "## Part 2A: Constructing the transition system and parametric MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47606ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Confusion Matrix (3 by 3 with pedestrian, obstacle, background)\n",
    "def construct_CM(tp_ped, tp_obj, tp_emp):\n",
    "    C = dict()\n",
    "    C[\"ped\", \"ped\"] = tp_ped\n",
    "    C[\"ped\", \"obj\"] = 0.1*(1-tp_ped)\n",
    "    C[\"ped\", \"empty\"] = 0.9*(1-tp_ped)\n",
    "    \n",
    "    C[\"obj\", \"ped\"] = 0.1*(1-tp_obj)\n",
    "    C[\"obj\", \"obj\"] = tp_obj\n",
    "    C[\"obj\", \"empty\"] = 0.9*(1-tp_obj)\n",
    "    \n",
    "    C[\"empty\", \"ped\"] = 0.5*(1-tp_emp)\n",
    "    C[\"empty\", \"obj\"] = 0.5*(1-tp_emp)\n",
    "    C[\"empty\", \"empty\"] = tp_emp\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c42b5ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that converts to a Markov chain from states and actions:\n",
    "def _construct_mdpmc(states, transitions, init, actions=None):\n",
    "    if actions is not None:\n",
    "        ts = MDP()\n",
    "        ts.actions.add_from(actions)\n",
    "    else:\n",
    "        ts = MC()\n",
    "    ts.states.add_from(states)\n",
    "    ts.states.initial.add(init)\n",
    "\n",
    "    for transition in transitions:\n",
    "        attr = {\"probability\": transition[2]}\n",
    "        if len(transition) > 3:\n",
    "            attr[\"action\"] = transition[3]\n",
    "        ts.transitions.add(\n",
    "            transition[0],\n",
    "            transition[1],\n",
    "            attr,\n",
    "        )\n",
    "\n",
    "    for s in states:\n",
    "        ts.atomic_propositions.add(s)\n",
    "        ts.states[s][\"ap\"] = {s}\n",
    "    return ts\n",
    "\n",
    "# Function to return a list of all combinations of inputs:\n",
    "# Input: A dictionary names D\n",
    "# Each key of D corresponds to a set of values that key can take\n",
    "# Output: All combinations of input keys\n",
    "def dict_combinations(D):\n",
    "    keys = D.keys()\n",
    "    values = list(D.values())\n",
    "    prod_input = list(product(*values))\n",
    "    return prod_input\n",
    "\n",
    "## Parametric Markov chain synthesis class:\n",
    "model_MC = \"model_MC.nm\"\n",
    "class MarkovChain:\n",
    "    def __init__(self, S, O, state_to_S):\n",
    "        self.states = S    # Product states for car.\n",
    "        self.state_dict = state_to_S\n",
    "        self.reverse_state_dict = {v: k for k, v in state_to_S.items()}\n",
    "        self.obs = O\n",
    "        self.true_env = None # This state is defined in terms of the observation\n",
    "        self.true_env_type = None # Type of the env object; is in one of obs\n",
    "        self.C = dict() # Confusion matrix dictionary giving: C[obs, true] =  P(obs |- phi | true |- phi)\n",
    "        self.M = dict() # Two-by-two dictionary. a(i,j) = Prob of transitioning from state i to state j\n",
    "        self.K = None # Depending on the observation, the controller changes. This is a dictionary of the controller after the Mealy machine is syntehsized from specifications\n",
    "        self.K_strategy = None # Dictionary containing the scripts to the controller after it has been written to file\n",
    "        self.formula = []\n",
    "        self.K_int_state_map = dict() # Nested dictionary mapping internal states to concrete states of the controller instantiation\n",
    "        self.K_int_state_map_inv = dict() # Nested dictionary mapping concrete states of controller instance into internal states\n",
    "        self.MC = None # A Tulip Markov chain object that is consistent with TuLiP transition system markov chain\n",
    "        self.true_env_MC = None # A Markov chain representing the true evolution of the environment\n",
    "        self.backup = dict() # This is a backup controller.\n",
    "\n",
    "    # Convert this Markov chain object into a tulip transition system:\n",
    "    def to_MC(self, init):\n",
    "        states = set(self.states) # Set of product states of the car\n",
    "        transitions = set()\n",
    "        for k in self.M.keys():\n",
    "            p_approx = min(1, abs(self.M[k])) # Probabilities cannot be greater than 1\n",
    "            if abs(1-self.M[k]) > 1e-2:\n",
    "                print(abs(1-self.M[k]))\n",
    "            t = (k[0], k[1], p_approx)\n",
    "            transitions |= {t}\n",
    "        assert init in self.states\n",
    "        self.MC = _construct_mdpmc(states, transitions, init)\n",
    "        markov_chain = _construct_mdpmc(states, transitions, init)\n",
    "        for state in self.MC.states:\n",
    "            self.MC.states[state][\"ap\"] = {state}\n",
    "        self.check_MC() # Checking if Markov chain is valid\n",
    "        return markov_chain\n",
    "\n",
    "# Writing/Printing Markov chains to file:\n",
    "    def print_MC(self):\n",
    "        model_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"models\")\n",
    "        path_MC = os.path.join(model_path, model_MC)\n",
    "        env_MC = os.path.join(model_path, \"env_MC.nm\")\n",
    "        path_MC_model = stormpy_int.build_stormpy_model(path_MC)\n",
    "        env_MC_model = stormpy_int.build_stormpy_model(env_MC)\n",
    "        stormpy_int.print_stormpy_model(path_MC_model)\n",
    "        stormpy_int.print_stormpy_model(env_MC_model)\n",
    "\n",
    "   # Function to check if all outgoing transition probabilities for any state in the Markov chain sum to 1.\n",
    "    def check_MC(self):\n",
    "        T = self.MC.transitions(data=True)\n",
    "        # Printing all states and outgoing transitions\n",
    "        for st in self.MC.states:\n",
    "            print(\"State: \", st)\n",
    "            end_states = [t for t in T if t[0]==st]\n",
    "            prob = [(t[2])['probability'] for t in end_states]\n",
    "            print(\"probability of end states: \", str(prob))\n",
    "            if not abs(sum(prob)-1)<1e-4:\n",
    "                pdb.set_trace()\n",
    "            assert abs(sum(prob)-1)<1e-4 # Checking that probabilities add up to 1 for every state\n",
    "\n",
    "   # Sets the state of the true environment\n",
    "   # True env type is the string form of the object and st is the corresponding state\n",
    "    def set_true_env_state(self, st, true_env_type):\n",
    "        self.true_env = st\n",
    "        new_st = \"p\"+st\n",
    "        states = {new_st}\n",
    "        transitions ={(new_st, new_st, 1)}\n",
    "        init = new_st\n",
    "        self.true_env_type = true_env_type\n",
    "        self.true_env_MC = _construct_mdpmc(states, transitions, init)\n",
    "\n",
    "    # Parametric confusion matrix:\n",
    "    def set_confusion_matrix(self, C):\n",
    "        self.C = C\n",
    "        \n",
    "    # Depending on the observation, the controller K changes. K should be a dictionary that maps observation to a controller. ToDo: Assess difference between K and K_strategy\n",
    "    def set_controller(self, K, K_strategy, K_backup):\n",
    "        self.K_strategy = K_strategy\n",
    "        self.K = K\n",
    "        self.backup = K_backup\n",
    "    \n",
    "    # Determining transition to next state based on the env observed in the current state\n",
    "    # This part is critical and depends on the controller corresponding to the predicted env state\n",
    "    def compute_next_state(self,obs,env_st, init_st): # The next state computed using the observation from the current state\n",
    "        Ki = self.K[obs] # The controller object\n",
    "        Ki_strategy =self.K_strategy[obs]\n",
    "        K_instant, sinit_adj, flg = self.adjust_state(Ki, Ki_strategy,obs,init_st) # If flg = 1, use sinit_adj as given by backup controller\n",
    "        if flg == 0:\n",
    "            next_st = K_instant.move(*env_st) # Might have to modify this when there are multiple observations\n",
    "        else:\n",
    "            next_st = {'xcar': sinit_adj[0], 'vcar': sinit_adj[1]}\n",
    "        return next_st\n",
    "\n",
    "    # Function to construct a map of internal states of various controllers:\n",
    "    # TODO: Debug\n",
    "    def construct_internal_state_maps(self):\n",
    "        for obs in self.obs:\n",
    "            Ki = self.K[obs]\n",
    "            Ki_strategy = self.K_strategy[obs]\n",
    "            inputs = Ki.inputs # Input dictionary mapping input variables to range of values\n",
    "            outputs = Ki.outputs # Output dictionary mapping output variable to range of values\n",
    "            input_comb = dict_combinations(inputs)\n",
    "            output_comb = dict_combinations(outputs)\n",
    "            K_inst = Ki_strategy.TulipStrategy() # Instantiation\n",
    "            N_int_states = K_inst.state # Total no. of internal states\n",
    "#             print(inputs)\n",
    "#             print(input_comb)\n",
    "#             print(\"Inputs: \")\n",
    "#             print(input_comb)\n",
    "#             print(\"Outputs: \")\n",
    "#             print(output_comb)\n",
    "            # Check --> good upto this point\n",
    "            self.K_int_state_map[Ki] = dict()\n",
    "            self.K_int_state_map_inv[Ki] = dict()\n",
    "            \n",
    "            # Instantiate a different input state map for different initial conditions that you can observe:\n",
    "            for inp in input_comb:\n",
    "                self.K_int_state_map[Ki][inp] = dict()\n",
    "                self.K_int_state_map_inv[Ki][inp] = dict()\n",
    "                # Populating the dictionary:\n",
    "                for ii in range(N_int_states):\n",
    "                    self.K_int_state_map[Ki][inp][ii] = None # None object\n",
    "\n",
    "            # Modifying the list:\n",
    "            for int_st in range(N_int_states+1):\n",
    "                # print(\"Internal state: \", str(int_st))\n",
    "                for inp in input_comb:\n",
    "                    K_inst.state = int_st # Modifying internal state to stay where it is\n",
    "                    # print(\"Input: \", str(inp))\n",
    "                    try: # Adding the environment state\n",
    "                        out = K_inst.move(*inp)\n",
    "                        state = K_inst.state\n",
    "                        # print(\"State moved: \", str(state))\n",
    "                        if (state == 2):\n",
    "                            flg = 1\n",
    "                        if self.K_int_state_map[Ki][inp][state] is None:\n",
    "                            # print(\"Output value: \", list(out.values()))\n",
    "                            self.K_int_state_map[Ki][inp][state] = list(out.values()) # Updating state\n",
    "                            assert self.K_int_state_map[Ki][inp][state] is not None\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "            # Reversing the internal state map:\n",
    "            # Adding only those states that are not of type None\n",
    "            for inp in input_comb:\n",
    "                for k,v in self.K_int_state_map[Ki][inp].items():\n",
    "                    if v is not None:\n",
    "                        self.K_int_state_map_inv[Ki][inp][tuple(v)] = k\n",
    "\n",
    "\n",
    "    # Adjust state of the system based on the controller that's being used so it doesn't throw an error:\n",
    "    # Ki is the controller and Ki_strategy is the script that corresponds to the strategy\n",
    "    # of Ki. One of the variables returned is also K_instant (the instantiation of the controller)\n",
    "    def adjust_state(self,Ki, Ki_strategy, obs,  sinit_st):\n",
    "        flg =0 # Default\n",
    "        inp_st = tuple(self.get_env_state(obs))\n",
    "        if sinit_st not in self.K_int_state_map_inv[Ki][inp_st].keys():\n",
    "            poss_st = self.backup[sinit_st]\n",
    "            test_list = [p for p in poss_st if (p[0]==sinit_st[0] and p[1]==1)]  # If sinit_st is at zero velocity, car should not remain stuck at 0 velocity.\n",
    "            flg = 1\n",
    "            K_instant = None\n",
    "            if test_list:\n",
    "                init_st_adj = test_list[0]\n",
    "            else:\n",
    "                init_st_adj = poss_st[0]\n",
    "        else:\n",
    "            init_st_adj=(self.K_int_state_map_inv[Ki][inp_st])[sinit_st] # Finding the mapping from internal states\n",
    "            print(\"Adjusted state: \", init_st_adj)\n",
    "            K_instant = Ki_strategy.TulipStrategy()\n",
    "            K_instant.state = init_st_adj\n",
    "        return K_instant, init_st_adj, flg\n",
    "\n",
    "    # Function to return the state of the environment given the observation:\n",
    "    def get_env_state(self, obs):\n",
    "        env_st =[1] # For static environment, env state is the same. Should modify this function for reactive environments\n",
    "        if obs == self.true_env_type:\n",
    "            env_st = [int(self.true_env)]\n",
    "        return env_st\n",
    "\n",
    "    # Constructing the Markov chain\n",
    "    def construct_markov_chain(self): # Construct probabilities and transitions in the markov chain given the controller and confusion matrix\n",
    "        for Si in list(self.states):\n",
    "            print(\"Finding initial states in the Markov chain: \")\n",
    "            print(Si)\n",
    "            init_st = self.reverse_state_dict[Si]\n",
    "            out_states = []\n",
    "            if init_st == (8,3) or init_st == (3,0):\n",
    "                pdb.set_trace()\n",
    "            # The output state can be different depending on the observation as defined by the confusion matrix\n",
    "            for obs in self.obs:\n",
    "                # print(\"The observation is as follows: \")\n",
    "                # print(obs)\n",
    "                env_st = self.get_env_state(obs)\n",
    "                next_st = self.compute_next_state(obs, env_st, init_st)\n",
    "                # print(\"The next state for this observation is as follows: \")\n",
    "                # print(next_st)\n",
    "                Sj = self.state_dict[tuple(next_st.values())]\n",
    "                try:\n",
    "                    prob_t = self.C[(obs, self.true_env_type)] # Parametric probability of transitions\n",
    "                except:\n",
    "                    pdb.set_trace()\n",
    "                if (Si, Sj) in self.M.keys():\n",
    "                    self.M[Si, Sj] = self.M[Si, Sj] + prob_t\n",
    "                else:\n",
    "                    self.M[Si, Sj] = prob_t\n",
    "                if Sj not in out_states:\n",
    "                    out_states.append(Sj)\n",
    "            sum_probs = sum([self.M[Si, Sj] for Sj in out_states])\n",
    "#             if init_st[0] <= 16:\n",
    "#                 if abs(1-sum_probs) > 1e-4:\n",
    "#                     pdb.set_trace() # Sanity check\n",
    "        return self.M\n",
    "    \n",
    "    # Adding formulae to list of temporal logic formulas:\n",
    "    def add_TL(self, phi):\n",
    "        self.formula.append(phi)\n",
    "\n",
    "    # Probabilistic satisfaction of a temporal logic with respect to a model:\n",
    "    def prob_TL(self, phi):\n",
    "        model_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"models\")\n",
    "        prism_file_path = os.path.join(model_path, \"pedestrian.nm\")\n",
    "        path_MC = os.path.join(model_path, model_MC)\n",
    "        env_MC = os.path.join(model_path, \"env_MC.nm\")\n",
    "        # Print self markov chain:\n",
    "        # print(self.MC)\n",
    "        # Writing prism files:\n",
    "        stormpy_int.to_prism_file(self.MC, path_MC)\n",
    "        stormpy_int.to_prism_file(self.true_env_MC, env_MC)\n",
    "        composed = synchronous_parallel([self.MC, self.true_env_MC])\n",
    "        # print(composed.transitions)\n",
    "        result = stormpy_int.model_checking(composed, phi, prism_file_path)\n",
    "        # Returns a tulip transys:\n",
    "        # MC_ts = stormpy_int.to_tulip_transys(path_MC)\n",
    "        result = stormpy_int.model_checking(self.MC, phi, prism_file_path) # Since there is no moving obstacle, try checking only the pedestrian obstacle\n",
    "        #for state in self.MC.states:\n",
    "        #    print(\"  State {}, with labels {}, Pr = {}\".format(state, self.MC.states[state][\"ap\"], result[str(state)]))\n",
    "        return result\n",
    "\n",
    "    # Function to append labels to a .nm file:\n",
    "    def add_labels(self, MAX_V):\n",
    "        model_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"models\")\n",
    "        path_MC = os.path.join(model_path, prop_model_MC)\n",
    "        for vi in range(0, MAX_V):\n",
    "            var = \"label \\\"v_\"+str(vi)+\"\\\"=\"\n",
    "            flg_var = 0 # Set after the first state is appended\n",
    "            for k, val in self.state_dict.items():\n",
    "                if k[1] == vi:\n",
    "                    if flg_var == 0:\n",
    "                        flg_var = 1\n",
    "                        var = var + \"(s = \"\n",
    "                    var = var + \"\"\n",
    "            with open(path_MC, 'a') as out:\n",
    "                out.write(var + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "facb20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_MC(K, K_backup, C, true_env, true_env_type, state_info, M):\n",
    "    importlib.reload(Kped)\n",
    "    importlib.reload(Kobj)\n",
    "    importlib.reload(Kempty)\n",
    "    \n",
    "    K_strat = dict()\n",
    "    K_strat[\"ped\"] = Kped\n",
    "    K_strat[\"obj\"] = Kobj\n",
    "    K_strat[\"empty\"] = Kempty\n",
    "    \n",
    "    obs_keys = dict()\n",
    "    obs_keys[\"ped\"] = [\"xcar\", \"vcar\"]\n",
    "    obs_keys[\"obj\"] = [\"xobj\"]\n",
    "    obs_keys[\"empty\"] = [\"xempty\"]\n",
    "    \n",
    "    M.set_confusion_matrix(C)\n",
    "    M.set_true_env_state(true_env, true_env_type)\n",
    "    M.set_controller(K, K_strat, K_backup)\n",
    "    \n",
    "    M.construct_internal_state_maps()\n",
    "    \n",
    "    # Construct Markov chain:\n",
    "    M.construct_markov_chain()\n",
    "    start_state = state_info[\"start\"]\n",
    "    bad_states = state_info[\"bad\"]\n",
    "    good_state = state_info[\"good\"]\n",
    "    MC = M.to_MC(start_state) # For setting initial conditions and assigning bad/good labels\n",
    "    print(M.M)\n",
    "    return M\n",
    "\n",
    "def initialize(vmax, MAX_V):\n",
    "    Ncar = int(MAX_V*(MAX_V+1)/2 + 10)\n",
    "    Vlow =  0\n",
    "    Vhigh = vmax\n",
    "    x_vmax_stop = MAX_V*(MAX_V+1)/2 + 1\n",
    "    xcross_start = 2\n",
    "    Nped = Ncar - xcross_start + 1\n",
    "    if x_vmax_stop >= xcross_start:\n",
    "        min_xped = int(x_vmax_stop + 1 - (xcross_start - 1))\n",
    "    else:\n",
    "        min_xped = 3\n",
    "    assert(min_xped > 0)\n",
    "    assert(min_xped<= Nped)\n",
    "    if min_xped < Nped:\n",
    "        xped = np.random.randint(min_xped, Nped)\n",
    "    else:\n",
    "        xped = int(min_xped)\n",
    "    xped = int(min_xped)\n",
    "    xcar_stop = xped + xcross_start - 2\n",
    "    assert(xcar_stop > 0)\n",
    "    state_f = lambda x,v: (Vhigh-Vlow+1)*(x-1)+v\n",
    "    bad_states = set()\n",
    "    good_state = set()\n",
    "    \n",
    "    def get_formula_states(xcar_stop):\n",
    "        bst = set()\n",
    "        for vi in range(0,Vhigh+1):\n",
    "            state = state_f(xcar_stop, vi)\n",
    "            bst |= {\"S\"+str(state)}\n",
    "        gst = {\"S\" + str(state_f(xcar_stop,0))}\n",
    "        bad = \"\" # Expression for bad states\n",
    "        good = \"\" # Expression for good states\n",
    "        for st in list(gst):\n",
    "            if good == \"\":\n",
    "                good = good + \"\\\"\" + st+\"\\\"\"\n",
    "            else:\n",
    "                good = good + \"|\\\"\"+st+\"\\\"\"\n",
    "        for st in list(bst):\n",
    "            if bad == \"\":\n",
    "                bad = bad + \"\\\"\" + st+\"\\\"\"\n",
    "            else:\n",
    "                bad = bad + \"|\\\"\"+st+\"\\\"\"\n",
    "        return good, bad, gst, bst\n",
    "    good, bad, gst, bst = get_formula_states(xcar_stop)\n",
    "    good_state |= gst\n",
    "    bad_states |= bst\n",
    "    formula = \"P=?[!(\"+str(bad)+\") U \"+str(good)+\"]\"\n",
    "    \n",
    "    phi1 = \"!(\"+good+\")\"\n",
    "    phi2 = \"(\"+good+\") | !(\"+bad\n",
    "    for xcar_ii in range(xcar_stop+1, Ncar+1):\n",
    "        good, bad, gst, bst = get_formula_states(xcar_ii) # We only want the bad states; ignore the good states output here\n",
    "        bad_states |= bst\n",
    "        phi2 = phi2 + \"|\" + bad\n",
    "    phi2 = phi2 + \")\"\n",
    "    formula = \"P=?[G(\"+str(phi1)+\") && G(\"+str(phi2)+\")]\"\n",
    "    return Ncar, Vlow, Vhigh, xcross_start, xped, bad_states, good_state, formula\n",
    "\n",
    "# Construct backup controller:\n",
    "def construct_backup_controller(Ncar, Vlow, Vhigh):\n",
    "    K_backup = dict()\n",
    "    for xcar in range(1,Ncar+1):\n",
    "        for vcar in range(Vlow, Vhigh+1):\n",
    "            st = (xcar, vcar)\n",
    "            end_st = []\n",
    "            if xcar == Ncar:\n",
    "                end_st.append((xcar, vcar))\n",
    "            elif vcar == 0:\n",
    "                xcar_p = min(Ncar, xcar+1)\n",
    "                end_st.append((xcar, vcar))\n",
    "                end_st.append((xcar_p, vcar+1))\n",
    "                end_st.append((xcar, vcar+1))\n",
    "            else:\n",
    "                xcar_p = min(Ncar, xcar+vcar)\n",
    "                end_st.append((xcar_p, vcar))\n",
    "                end_st.append((xcar_p, vcar-1))\n",
    "                if vcar < Vhigh:\n",
    "                    end_st.append((xcar_p, vcar+1))\n",
    "            K_backup[st] = end_st\n",
    "    return K_backup\n",
    "\n",
    "# Creating the states of the markov chain for the system:\n",
    "# Returns product states S and (pos,vel) to state dictionary\n",
    "def system_states_example_ped(Ncar, Vlow, Vhigh):\n",
    "    nS = Ncar*(Vhigh-Vlow+1)\n",
    "    state = lambda x,v: (Vhigh-Vlow+1)*(x-1) + v\n",
    "    state_to_S = dict()\n",
    "    S = set()\n",
    "    for xcar in range(1,Ncar+1):\n",
    "        for vcar in range(Vlow, Vhigh+1):\n",
    "            st = \"S\"+str(state(xcar, vcar))\n",
    "            state_to_S[xcar,vcar] = st\n",
    "            S|={st}\n",
    "    K_backup = construct_backup_controller(Ncar, Vlow, Vhigh)\n",
    "    return S, state_to_S, K_backup\n",
    "\n",
    "def get_states_and_controllers(C, M, start_state, good_state, bad_states, K, K_backup):\n",
    "    true_env = str(1) #Sidewalk 3\n",
    "    true_env_type = \"empty\"\n",
    "    state_info = dict()\n",
    "    state_info[\"start\"] = start_state\n",
    "    state_info[\"bad\"] = bad_states\n",
    "    state_info[\"good\"] = good_state\n",
    "    for st in list(good_state):\n",
    "        formula2 = 'P=?[G!(\\\"'+st+'\\\")]'\n",
    "    MC = call_MC(K, K_backup, C, true_env, true_env_type, state_info, M)\n",
    "    # result = M.prob_TL(formula)\n",
    "    result2 = MC.prob_TL(formula2)\n",
    "    print('Probability of eventually reaching good state for initial speed, {}, and max speed, {} is p = {}:'.format(vcar, vmax, result2[start_state]))\n",
    "    return result2[start_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd6e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 0 nodes from 14 total\n",
      "removed 0 nodes from 16 total\n",
      "removed 0 nodes from 7 total\n",
      "Finding initial states in the Markov chain: \n",
      "S59\n",
      "Finding initial states in the Markov chain: \n",
      "S146\n",
      "Finding initial states in the Markov chain: \n",
      "S107\n",
      "Finding initial states in the Markov chain: \n",
      "S75\n",
      "Finding initial states in the Markov chain: \n",
      "S17\n",
      "Finding initial states in the Markov chain: \n",
      "S78\n",
      "Finding initial states in the Markov chain: \n",
      "S127\n",
      "Adjusted state:  11\n",
      "Finding initial states in the Markov chain: \n",
      "S105\n",
      "Finding initial states in the Markov chain: \n",
      "S120\n",
      "Finding initial states in the Markov chain: \n",
      "S49\n",
      "Finding initial states in the Markov chain: \n",
      "S97\n",
      "Adjusted state:  6\n",
      "Finding initial states in the Markov chain: \n",
      "S47\n",
      "Finding initial states in the Markov chain: \n",
      "S50\n",
      "Finding initial states in the Markov chain: \n",
      "S142\n",
      "Finding initial states in the Markov chain: \n",
      "S56\n",
      "Finding initial states in the Markov chain: \n",
      "S135\n",
      "Finding initial states in the Markov chain: \n",
      "S101\n",
      "Finding initial states in the Markov chain: \n",
      "S4\n",
      "Finding initial states in the Markov chain: \n",
      "S113\n",
      "Finding initial states in the Markov chain: \n",
      "S137\n",
      "Finding initial states in the Markov chain: \n",
      "S85\n",
      "Adjusted state:  4\n",
      "Adjusted state:  5\n",
      "Finding initial states in the Markov chain: \n",
      "S126\n",
      "Finding initial states in the Markov chain: \n",
      "S140\n",
      "Finding initial states in the Markov chain: \n",
      "S21\n",
      "Finding initial states in the Markov chain: \n",
      "S76\n",
      "Finding initial states in the Markov chain: \n",
      "S38\n",
      "Finding initial states in the Markov chain: \n",
      "S133\n",
      "Adjusted state:  12\n",
      "Finding initial states in the Markov chain: \n",
      "S22\n",
      "Finding initial states in the Markov chain: \n",
      "S138\n",
      "Finding initial states in the Markov chain: \n",
      "S8\n",
      "Finding initial states in the Markov chain: \n",
      "S15\n",
      "Finding initial states in the Markov chain: \n",
      "S93\n",
      "Finding initial states in the Markov chain: \n",
      "S74\n",
      "Adjusted state:  3\n",
      "Adjusted state:  4\n",
      "Finding initial states in the Markov chain: \n",
      "S3\n",
      "Finding initial states in the Markov chain: \n",
      "S89\n",
      "Finding initial states in the Markov chain: \n",
      "S123\n",
      "Finding initial states in the Markov chain: \n",
      "S129\n",
      "Finding initial states in the Markov chain: \n",
      "S52\n",
      "Finding initial states in the Markov chain: \n",
      "S20\n",
      "Finding initial states in the Markov chain: \n",
      "S33\n",
      "Finding initial states in the Markov chain: \n",
      "S54\n",
      "Finding initial states in the Markov chain: \n",
      "S2\n",
      "Finding initial states in the Markov chain: \n",
      "S61\n",
      "Finding initial states in the Markov chain: \n",
      "S66\n",
      "Finding initial states in the Markov chain: \n",
      "S96\n",
      "Finding initial states in the Markov chain: \n",
      "S94\n",
      "Finding initial states in the Markov chain: \n",
      "S68\n",
      "Finding initial states in the Markov chain: \n",
      "S99\n",
      "Finding initial states in the Markov chain: \n",
      "S34\n",
      "Adjusted state:  1\n",
      "Adjusted state:  2\n",
      "Finding initial states in the Markov chain: \n",
      "S36\n",
      "Finding initial states in the Markov chain: \n",
      "S121\n",
      "Adjusted state:  10\n",
      "Finding initial states in the Markov chain: \n",
      "S5\n",
      "Adjusted state:  0\n",
      "Adjusted state:  0\n",
      "Adjusted state:  1\n",
      "Finding initial states in the Markov chain: \n",
      "S143\n",
      "Finding initial states in the Markov chain: \n",
      "S65\n",
      "Adjusted state:  2\n",
      "Finding initial states in the Markov chain: \n",
      "S87\n",
      "Finding initial states in the Markov chain: \n",
      "S117\n",
      "Finding initial states in the Markov chain: \n",
      "S0\n",
      "Finding initial states in the Markov chain: \n",
      "S29\n",
      "Finding initial states in the Markov chain: \n",
      "S124\n",
      "Finding initial states in the Markov chain: \n",
      "S134\n",
      "Finding initial states in the Markov chain: \n",
      "S141\n",
      "Finding initial states in the Markov chain: \n",
      "S130\n",
      "Finding initial states in the Markov chain: \n",
      "S73\n",
      "Finding initial states in the Markov chain: \n",
      "S136\n",
      "Finding initial states in the Markov chain: \n",
      "S46\n",
      "Finding initial states in the Markov chain: \n",
      "S24\n",
      "Finding initial states in the Markov chain: \n",
      "S32\n",
      "Finding initial states in the Markov chain: \n",
      "S90\n",
      "Adjusted state:  6\n",
      "Finding initial states in the Markov chain: \n",
      "S88\n",
      "Finding initial states in the Markov chain: \n",
      "S30\n",
      "Finding initial states in the Markov chain: \n",
      "S109\n",
      "Adjusted state:  8\n",
      "Finding initial states in the Markov chain: \n",
      "S11\n",
      "Finding initial states in the Markov chain: \n",
      "S92\n",
      "Finding initial states in the Markov chain: \n",
      "S10\n",
      "Finding initial states in the Markov chain: \n",
      "S62\n",
      "Finding initial states in the Markov chain: \n",
      "S119\n",
      "Finding initial states in the Markov chain: \n",
      "S122\n",
      "Finding initial states in the Markov chain: \n",
      "S63\n",
      "Finding initial states in the Markov chain: \n",
      "S86\n",
      "Finding initial states in the Markov chain: \n",
      "S16\n",
      "Finding initial states in the Markov chain: \n",
      "S1\n",
      "Finding initial states in the Markov chain: \n",
      "S108\n",
      "Finding initial states in the Markov chain: \n",
      "S19\n",
      "Finding initial states in the Markov chain: \n",
      "S44\n",
      "Finding initial states in the Markov chain: \n",
      "S37\n",
      "Finding initial states in the Markov chain: \n",
      "S14\n",
      "Finding initial states in the Markov chain: \n",
      "S106\n",
      "Finding initial states in the Markov chain: \n",
      "S45\n",
      "> \u001b[0;32m/var/folders/hz/k2w5mcvs7_xfg7cxqbdjfdzr0000gn/T/ipykernel_61075/1098834401.py\u001b[0m(227)\u001b[0;36mconstruct_markov_chain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    225 \u001b[0;31m                \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    226 \u001b[0;31m            \u001b[0;31m# The output state can be different depending on the observation as defined by the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 227 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    228 \u001b[0;31m                \u001b[0;31m# print(\"The observation is as follows: \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    229 \u001b[0;31m                \u001b[0;31m# print(obs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> init_st\n",
      "(8, 3)\n"
     ]
    }
   ],
   "source": [
    "MAX_V = 5\n",
    "vmax = MAX_V\n",
    "Ncar, Vlow, Vhigh, xcross_start, xped, bad_states, good_state, formula = initialize(vmax, MAX_V)\n",
    "\n",
    "# Construct state (x,v) back from state:\n",
    "def state_f(x,v):\n",
    "    S_value = (Vhigh-Vlow+1)*(x-1) + v\n",
    "    return S_value\n",
    "\n",
    "# Generate probability points from Confusion Matrix:\n",
    "def gen_points():\n",
    "    points_ped = [] # Satisfaction probabilities for true env as ped\n",
    "    points_obj = [] # Satisfaction probabilities for true env as ped\n",
    "    points_emp = [] # Satisfaction probabilities for true env as ped\n",
    "       \n",
    "    vcar = 5 # Initial speed at starting point\n",
    "    start_state = \"S\"+str(state_f(1,vcar))\n",
    "    S, state_to_S, K_backup = system_states_example_ped(Ncar, Vlow, Vhigh)\n",
    "    O = {\"ped\", \"obj\", \"empty\"}\n",
    "    K = K_des.construct_controllers(Ncar, Vlow, Vhigh, xped, vcar, xcross_start)\n",
    "    M = MarkovChain(S, O, state_to_S)\n",
    "    \n",
    "    tp_range = np.linspace(0.6, 0.99, num=5)\n",
    "    for tp_ped in tp_range:\n",
    "        tp_obj = 0.8\n",
    "        tp_emp = 0.8\n",
    "        C = construct_CM(tp_ped, tp_obj, tp_emp)\n",
    "        prob = get_states_and_controllers(C, M, start_state, good_state, bad_states, K, K_backup)\n",
    "        points_ped.append(prob)\n",
    "    print(\"Found probabilities for pedestrian env!\")\n",
    "    \n",
    "    for tp_obj in tp_range:\n",
    "        tp_ped = 0.8\n",
    "        tp_emp = 0.8\n",
    "        C = construct_CM(tp_ped, tp_obj, tp_emp)\n",
    "        prob = get_states_and_controllers(C, M, start_state, good_state, bad_states, K, K_backup)\n",
    "        points_obj.append(prob)\n",
    "    print(\"Found probabilities for obj env!\")\n",
    "    \n",
    "    for tp_emp in tp_range:\n",
    "        tp_obj = 0.8\n",
    "        tp_ped = 0.8\n",
    "        C = construct_CM(tp_ped, tp_obj, tp_emp)\n",
    "        prob = get_states_and_controllers(C, M, start_state, good_state, bad_states, K, K_backup)\n",
    "        points_emp.append(prob)\n",
    "    return points_ped, points_obj, points_emp\n",
    "\n",
    "points_ped, points_obj, points_emp = gen_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3189819",
   "metadata": {},
   "source": [
    "## Part 3: Controller Contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc58078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd502b2f",
   "metadata": {},
   "source": [
    "## Part 4: Computing desired probabilities for Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab90883c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
